
<p align="center">
  <h3 align="center"><strong>MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies</strong></h3>
</p>

<p align="center">
  Long Yang<sup>*</sup>&nbsp;&nbsp;&nbsp;
  <a href="https://zhenglianqing.github.io/">Lianqing Zheng</a><sup>*</sup>&nbsp;&nbsp;&nbsp;
  Wenjin Ai</sup>&nbsp;&nbsp;&nbsp;
  Minghao Liu</sup>&nbsp;&nbsp;&nbsp;
  Sen Li</sup>&nbsp;&nbsp;&nbsp;
  Qunshu Lin</sup>&nbsp;&nbsp;&nbsp;
  Shengyu Yan</sup>&nbsp;&nbsp;&nbsp;
  Jie Bai</sup>&nbsp;&nbsp;&nbsp;
  Zhixiong Ma</sup>&nbsp;&nbsp;&nbsp;
  Tao Huang</sup>&nbsp;&nbsp;&nbsp;
  Xichan Zhu</sup>&nbsp;&nbsp;&nbsp;
</p>

<p align="center">
  <a href="https://arxiv.org/pdf/2501.15384" target='_blank'>
    <img src="https://img.shields.io/badge/Paper-%F0%9F%93%83-purple">
  </a>

  <a href="https://github.com/TJRadarLab/OmniHD-Scenes" target='_blank'>
    <img src="https://img.shields.io/badge/OmniHD--Scenes-ðŸ“¦-violet">
  </a>

  <a href="https://github.com/weiyithu/SurroundOcc/blob/main/docs/data.md" target='_blank'>
    <img src="https://img.shields.io/badge/SurroundOcc--nuScenes-ðŸ“¦-blu">
  </a>
  
</p>

## Overview
This repository is an official implementation of MetaOcc, the first framework to fuse surround-view 4D radar and camera data for robust and annotation-efficient 3D occupancy prediction in autonomous driving.
<div style="text-align: center;">
    <img src="assets\framework.png" alt="Dialogue_Teaser" width=100% >
</div>


## Results
- 3D semantic occupancy prediction results on [nuScenes](https://github.com/nutonomy/nuscenes-devkit).
<div style="text-align: center;">
    <img src="assets\SurroundOcc_nuScenes_Result.png" alt="Dialogue_Teaser" width=100% >
</div>

- 3D semantic occupancy prediction results on [OmniHD-Scenes](https://github.com/TJRadarLab/OmniHD-Scenes).
<div style="text-align: center;">
    <img src="assets\OmniHD_Scenes_Result.png" alt="Dialogue_Teaser" width=100% >
</div>


## Updates
`[2025/8/12]` ðŸŽ‰ OmniHD-Scenes dataset v1.0 (~1.3TB) is openly for research purposes. Apply for download [here](https://www.2077ai.com/contact) and explore it via the [official repository](https://github.com/TJRadarLab/OmniHD-Scenes).

`[2025/1/31]` ðŸš€ Our paper is available on [arXiv](https://arxiv.org/pdf/2501.15384). Code will be released soon!